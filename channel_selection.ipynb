{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datahandling import BcomMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_re_144-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_i_116-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_a_112-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ri_146-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_sa_152-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ma_132-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "18 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ra_142-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_te_164-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_si_156-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_li_126-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ta_162-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ti_166-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_e_114-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_mi_136-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_se_154-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_la_122-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_me_134-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_le_124-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "7 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "dir = '/Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT'\n",
    "epo_files = []\n",
    "subjects = ['BCOM_18_2']\n",
    "avoid_reading = False\n",
    "data = BcomMEG(dir=dir, subjects=subjects, avoid_reading=avoid_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "178 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "123 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "# first, sepreate out the conditions\n",
    "a_labels = [a for a in data.data['BCOM_18_2'].keys() if 'a' in a]\n",
    "e_labels = [e for e in data.data['BCOM_18_2'].keys() if 'e' in e]\n",
    "i_labels = [i for i in data.data['BCOM_18_2'].keys() if 'i' in i]\n",
    "\n",
    "for subject in data.data:\n",
    "    a_epochs = mne.concatenate_epochs([data.data[subject][a] for a in a_labels])\n",
    "    e_epochs = mne.concatenate_epochs([data.data[subject][e] for e in e_labels])\n",
    "    i_epochs = mne.concatenate_epochs([data.data[subject][i] for i in i_labels])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "178 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "123 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "141 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "126 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "142 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "epochs[1].info['dev_head_t'] differs. The instances probably come from different runs, and are therefore associated with different head positions. Manually change info['dev_head_t'] to avoid this message but beware that this means the MEG sensors will not be properly spatially aligned. See mne.preprocessing.maxwell_filter to realign the runs to a common head position.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     e_epochs\u001b[38;5;241m.\u001b[39mappend(mne\u001b[38;5;241m.\u001b[39mconcatenate_epochs([data\u001b[38;5;241m.\u001b[39mdata[subject][e] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m e_labels \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdata[subject]\u001b[38;5;241m.\u001b[39mkeys()]))\n\u001b[1;32m     25\u001b[0m     i_epochs\u001b[38;5;241m.\u001b[39mappend(mne\u001b[38;5;241m.\u001b[39mconcatenate_epochs([data\u001b[38;5;241m.\u001b[39mdata[subject][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m i_labels \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdata[subject]\u001b[38;5;241m.\u001b[39mkeys()]))\n\u001b[0;32m---> 27\u001b[0m a_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m e_epochs \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mconcatenate_epochs(e_epochs)\n\u001b[1;32m     29\u001b[0m i_epochs \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mconcatenate_epochs(i_epochs)\n",
      "File \u001b[0;32m<decorator-gen-235>:12\u001b[0m, in \u001b[0;36mconcatenate_epochs\u001b[0;34m(epochs_list, add_offset, on_mismatch, verbose)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/epochs.py:4682\u001b[0m, in \u001b[0;36mconcatenate_epochs\u001b[0;34m(epochs_list, add_offset, on_mismatch, verbose)\u001b[0m\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_epochs\u001b[39m(\n\u001b[1;32m   4640\u001b[0m     epochs_list, add_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, on_mismatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4641\u001b[0m ):\n\u001b[1;32m   4642\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Concatenate a list of `~mne.Epochs` into one `~mne.Epochs` object.\u001b[39;00m\n\u001b[1;32m   4643\u001b[0m \n\u001b[1;32m   4644\u001b[0m \u001b[38;5;124;03m    .. note:: Unlike `~mne.concatenate_raws`, this function does **not**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.9.0\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m     (\n\u001b[1;32m   4671\u001b[0m         info,\n\u001b[1;32m   4672\u001b[0m         data,\n\u001b[1;32m   4673\u001b[0m         raw_sfreq,\n\u001b[1;32m   4674\u001b[0m         events,\n\u001b[1;32m   4675\u001b[0m         event_id,\n\u001b[1;32m   4676\u001b[0m         tmin,\n\u001b[1;32m   4677\u001b[0m         tmax,\n\u001b[1;32m   4678\u001b[0m         metadata,\n\u001b[1;32m   4679\u001b[0m         baseline,\n\u001b[1;32m   4680\u001b[0m         selection,\n\u001b[1;32m   4681\u001b[0m         drop_log,\n\u001b[0;32m-> 4682\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_epochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4685\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4687\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4688\u001b[0m     selection \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere([\u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m drop_log])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   4689\u001b[0m     out \u001b[38;5;241m=\u001b[39m EpochsArray(\n\u001b[1;32m   4690\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   4691\u001b[0m         info\u001b[38;5;241m=\u001b[39minfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4701\u001b[0m         raw_sfreq\u001b[38;5;241m=\u001b[39mraw_sfreq,\n\u001b[1;32m   4702\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/epochs.py:4541\u001b[0m, in \u001b[0;36m_concatenate_epochs\u001b[0;34m(epochs_list, with_data, add_offset, on_mismatch)\u001b[0m\n\u001b[1;32m   4539\u001b[0m warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   4540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epochs_list[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 4541\u001b[0m     \u001b[43m_ensure_infos_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs[\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mii\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_mismatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(epochs\u001b[38;5;241m.\u001b[39mtimes, epochs_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtimes):\n\u001b[1;32m   4543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs must have same times\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/_fiff/meas_info.py:3681\u001b[0m, in \u001b[0;36m_ensure_infos_match\u001b[0;34m(info1, info2, name, on_mismatch)\u001b[0m\n\u001b[1;32m   3662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (info1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_head_t\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m^\u001b[39m (info2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_head_t\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3663\u001b[0m     info1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_head_t\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3664\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3669\u001b[0m     )\n\u001b[1;32m   3670\u001b[0m ):\n\u001b[1;32m   3671\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3672\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.info[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev_head_t\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] differs. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3673\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances probably come from different runs, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3679\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns to a common head position.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3680\u001b[0m     )\n\u001b[0;32m-> 3681\u001b[0m     \u001b[43m_on_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_mismatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_mismatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/utils/check.py:1191\u001b[0m, in \u001b[0;36m_on_missing\u001b[0;34m(on_missing, msg, name, error_klass)\u001b[0m\n\u001b[1;32m   1189\u001b[0m on_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1193\u001b[0m     warn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: epochs[1].info['dev_head_t'] differs. The instances probably come from different runs, and are therefore associated with different head positions. Manually change info['dev_head_t'] to avoid this message but beware that this means the MEG sensors will not be properly spatially aligned. See mne.preprocessing.maxwell_filter to realign the runs to a common head position."
     ]
    }
   ],
   "source": [
    "# first, sepreate out the conditions\n",
    "a_labels = []\n",
    "e_labels = []\n",
    "i_labels = []\n",
    "for subject in data.data.keys():\n",
    "    for condition in data.data[subject].keys():\n",
    "        if 'a' in condition:\n",
    "            a_labels.append(condition)\n",
    "        elif 'e' in condition:\n",
    "            e_labels.append(condition)\n",
    "        elif 'i' in condition:\n",
    "            i_labels.append(condition)\n",
    "\n",
    "a_labels = set(a_labels)\n",
    "i_labels = set(i_labels)\n",
    "e_labels = set(e_labels)\n",
    "\n",
    "a_epochs = []\n",
    "e_epochs = []\n",
    "i_epochs = []\n",
    "\n",
    "for subject in data.data:\n",
    "    a_epochs.append(mne.concatenate_epochs([data.data[subject][a] for a in a_labels if a in data.data[subject].keys()]))\n",
    "    e_epochs.append(mne.concatenate_epochs([data.data[subject][e] for e in e_labels if e in data.data[subject].keys()]))\n",
    "    i_epochs.append(mne.concatenate_epochs([data.data[subject][i] for i in i_labels if i in data.data[subject].keys()]))\n",
    "\n",
    "a_epochs = mne.concatenate_epochs(a_epochs)\n",
    "e_epochs = mne.concatenate_epochs(e_epochs)\n",
    "i_epochs = mne.concatenate_epochs(i_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_test\n",
    "\n",
    "permuataion_collection = [a_epochs.get_data(), e_epochs.get_data(), i_epochs.get_data()]\n",
    "T_obs, clusters, cluster_p_values, H0 = permutation_cluster_test(permuataion_collection, n_permutations=2000, tail=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_sensors = np.where(cluster_p_values < 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Best sensors based on mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "num_a = len(a_epochs)\n",
    "num_e = len(e_epochs)\n",
    "num_i = len(i_epochs)\n",
    "min_trials = (min(num_a, num_e, num_i))\n",
    "\n",
    "a_rand = a_epochs[np.random.choice(num_a, min(num_a, num_e, num_i), replace=False)]\n",
    "e_rand = e_epochs[np.random.choice(num_e, min(num_a, num_e, num_i), replace=False)]\n",
    "i_rand = i_epochs[np.random.choice(num_i, min(num_a, num_e, num_i), replace=False)]\n",
    "\n",
    "a_data = a_rand.get_data()\n",
    "e_data = e_rand.get_data()\n",
    "i_data = i_rand.get_data()\n",
    "\n",
    "a_flat = a_data.reshape(a_data.shape[0], -1)\n",
    "e_flat = e_data.reshape(e_data.shape[0], -1)\n",
    "i_flat = i_data.reshape(i_data.shape[0], -1)\n",
    "\n",
    "\n",
    "X = np.vstack([a_flat, e_flat, i_flat])\n",
    "y = np.concatenate([np.ones(min_trials), np.ones(min_trials)*2, np.ones(min_trials)*3])\n",
    "mi_scores = mutual_info_classif(X, y, random_state=0)\n",
    "important_sensors = np.argsort(mi_scores)[-10:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_reshaped = mi_scores.reshape(a_data.shape[1], a_data.shape[2])\n",
    "sensor_mi_scores_reshaped = mi_reshaped.mean(axis=1)\n",
    "important_sensors = np.argsort(sensor_mi_scores_reshaped)[-10:]\n",
    "sensor_names = a_epochs.info['ch_names']\n",
    "important_sensor_names = [sensor_names[i] for i in important_sensors]\n",
    "print(important_sensor_names)\n",
    "sensor_mi_scores_reshaped[important_sensors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne.channels\n",
    "\n",
    "\n",
    "important_sensor_names\n",
    "sensor_mi_scores_reshaped[important_sensors]\n",
    "\n",
    "info = a_epochs.info\n",
    "picks = mne.pick_channels(info['ch_names'], include=important_sensor_names)\n",
    "\n",
    "pos = mne.channels.layout._find_topomap_coords(info, picks)\n",
    "\n",
    "data = np.array(sensor_mi_scores_reshaped[important_sensors])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_topomap(data, pos, axes=ax, show=False, cmap='viridis', contours=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok so where in the brain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the source space with the following parameters:\n",
      "\n",
      "SUBJECTS_DIR = /Users/ciprianbangu/mne_data/MNE-fsaverage-data\n",
      "Subject      = fsaverage\n",
      "Surface      = white\n",
      "Octahedron subdivision grade 6\n",
      "\n",
      ">>> 1. Creating the source space...\n",
      "\n",
      "Doing the octahedral vertex picking...\n",
      "Loading /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/surf/lh.white...\n",
      "Mapping lh fsaverage -> oct (6) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/surf/lh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded lh.white 4098/163842 selected to source space (oct = 6)\n",
      "\n",
      "Loading /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/surf/rh.white...\n",
      "Mapping rh fsaverage -> oct (6) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/surf/rh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded rh.white 4098/163842 selected to source space (oct = 6)\n",
      "\n",
      "Calculating source space distances (limit=inf mm)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m transformation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# standard source space and BEM model - \"Boundary Element Method\" model. i.e., a realistic head model to use for source localization. \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# apparently it deifnes the el\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_source_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfsaverage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moct6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 5 mins\u001b[39;00m\n\u001b[1;32m     12\u001b[0m bem \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mmake_bem_model(subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m, subjects_dir\u001b[38;5;241m=\u001b[39mbem_dir) \n\u001b[1;32m     14\u001b[0m bem \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mmake_bem_solution(bem)\n",
      "File \u001b[0;32m<decorator-gen-285>:12\u001b[0m, in \u001b[0;36msetup_source_space\u001b[0;34m(subject, spacing, surface, subjects_dir, add_dist, n_jobs, verbose)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/source_space/_source_space.py:1592\u001b[0m, in \u001b[0;36msetup_source_space\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_dist:\n\u001b[1;32m   1591\u001b[0m     dist_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_dist \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m-> 1592\u001b[0m     \u001b[43madd_source_space_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[38;5;66;03m# write out if requested, then return the data\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are now one step closer to computing the gain matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<decorator-gen-290>:12\u001b[0m, in \u001b[0;36madd_source_space_distances\u001b[0;34m(src, dist_limit, n_jobs, verbose)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/source_space/_source_space.py:2731\u001b[0m, in \u001b[0;36madd_source_space_distances\u001b[0;34m(src, dist_limit, n_jobs, verbose)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         s[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2731\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvertno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvertno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2735\u001b[0m     \u001b[38;5;66;03m# deal with indexing so we can add patch info\u001b[39;00m\n\u001b[1;32m   2736\u001b[0m     min_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dd[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m dd \u001b[38;5;129;01min\u001b[39;00m d])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/parallel.py:127\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[0;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_verbose\u001b[39m(\u001b[38;5;241m*\u001b[39margs, verbose\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m use_log_level(verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/source_space/_source_space.py:2781\u001b[0m, in \u001b[0;36m_do_src_distances\u001b[0;34m(con, vertno, run_inds, limit)\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m li, (l1, l2) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(lims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], lims[\u001b[38;5;241m1\u001b[39m:])):\n\u001b[1;32m   2780\u001b[0m     idx \u001b[38;5;241m=\u001b[39m vertno[run_inds[l1:l2]]\n\u001b[0;32m-> 2781\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2782\u001b[0m     midx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(out, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2783\u001b[0m     min_idx[li] \u001b[38;5;241m=\u001b[39m idx[midx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "subject_dir = os.path.expanduser('~/mne_data/MNE-fsaverage-data')\n",
    "bem_dir = os.path.expanduser('~/mne_data/MNE-fsaverage-data/')\n",
    "# head transformation, need to use average because no MRIs\n",
    "transformation = 'fsaverage'\n",
    "\n",
    "# standard source space and BEM model - \"Boundary Element Method\" model. i.e., a realistic head model to use for source localization. \n",
    "# apparently it deifnes the el\n",
    "\n",
    "src = mne.setup_source_space(subject='fsaverage', spacing='oct6', subjects_dir=subject_dir) # 5 mins\n",
    "\n",
    "bem = mne.make_bem_model(subject='fsaverage', subjects_dir=bem_dir) \n",
    "\n",
    "bem = mne.make_bem_solution(bem)\n",
    "\n",
    "# only for the chosen sensors\n",
    "\n",
    "picks = mne.pick_channels(info['ch_names'], include=important_sensor_names)\n",
    "\n",
    "# forward model\n",
    "\n",
    "fwd = mne.make_forward_solution(info=a_epochs.info, trans=transformation, src=src, bem=bem, eeg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10 out of 247 channels remain after picking\n"
     ]
    }
   ],
   "source": [
    "# get it for only certain channels\n",
    "\n",
    "picks = mne.pick_channels(fwd['info']['ch_names'], include=important_sensor_names)\n",
    "fwd_selected = mne.pick_channels_forward(fwd, include=important_sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data rank from 247 -> 247\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using DIAGONAL_FIXED\n",
      "    MAG regularization : 0.1\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "    MAG regularization : 0.1\n",
      "    MAG regularization : 0.1\n",
      "    MAG regularization : 0.1\n",
      "Number of samples used : 28197\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -1368.100\n",
      "   empirical: -1368.259\n",
      "   diagonal_fixed: -1427.716\n",
      "selecting best estimator: shrunk\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 10 channels.\n",
      "    10 out of 10 channels remain after picking\n",
      "Selected 10 channels\n",
      "Creating the depth weighting matrix...\n",
      "    10 magnetometer or axial gradiometer channels\n",
      "    limit = 7980/8196 = 10.006894\n",
      "    scale = 4.50088e-12 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.5e-16 (2.2e-16 eps * 10 dim * 0.16  max singular value)\n",
      "    Estimated rank (mag): 10\n",
      "    MAG: rank 10 computed from 10 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 1.59682\n",
      "    scaling factor to adjust the trace = 8.10551e+17 (nchan = 10 nzero = 0)\n"
     ]
    }
   ],
   "source": [
    "# Computing the inverse model:\n",
    "\n",
    "noise_cov = mne.compute_covariance(a_epochs, method='auto')\n",
    "\n",
    "# create an inverse operator to convert signals to brain activity\n",
    "\n",
    "inv = mne.minimum_norm.make_inverse_operator(info=a_epochs.info, forward=fwd_selected, noise_cov=noise_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lambda2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m9.0\u001b[39m \u001b[38;5;66;03m# regularization parameter\u001b[39;00m\n\u001b[1;32m      4\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdSPM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# or \"dSPM\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stc \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mminimum_norm\u001b[38;5;241m.\u001b[39mapply_inverse(a_epochs\u001b[38;5;241m.\u001b[39maverage(), \u001b[43minv\u001b[49m, lambda2, method)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inv' is not defined"
     ]
    }
   ],
   "source": [
    "# computing source esitmation\n",
    "\n",
    "lambda2 = 1.0 / 9.0 # regularization parameter\n",
    "method = \"dSPM\" # or \"dSPM\"\n",
    "\n",
    "stc = mne.minimum_norm.apply_inverse(a_epochs.average(), inv, lambda2, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... Idk if this shows what I want it to show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.26156745 3.43162634 4.04986332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x17bd27a50> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3d2827b40> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160490780> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160491b10> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160496630> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160497860> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x1604981b0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160499c70> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x396aa32a0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x16049ba50> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3bc36c2f0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3bc3320b0> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "brain = stc.plot(hemi='split', subjects_dir=subject_dir, subject='fsaverage', time_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak activation at vertex 86178 at 0.21666666666666673 seconds\n"
     ]
    }
   ],
   "source": [
    "peak_vertex, peak_time = stc.get_peak()\n",
    "print(f\"Peak activation at vertex {peak_vertex} at {peak_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 35 labels from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/label/lh.aparc.annot\n",
      "   read 34 labels from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/label/rh.aparc.annot\n",
      "Extracting time courses for 68 labels (mode: mean)\n",
      "Label with strongest average activity: lateraloccipital-lh\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Read labels for fsaverage (Desikan-Killiany \"aparc\" parcellation)\n",
    "labels = mne.read_labels_from_annot(\n",
    "    subject='fsaverage', \n",
    "    parc='aparc', \n",
    "    subjects_dir=subject_dir\n",
    ")\n",
    "\n",
    "# one of them is missing i guess?\n",
    "labels = [label for label in labels if 'unknown' not in label.name]\n",
    "\n",
    "# Extract mean time course from each label\n",
    "label_ts = mne.extract_label_time_course(\n",
    "    stc, \n",
    "    labels, \n",
    "    src=src, \n",
    "    mode='mean'\n",
    ")\n",
    "# label_ts: shape (n_labels, n_times)\n",
    "\n",
    "# Find label with largest mean activity over time\n",
    "mean_act = np.mean(np.abs(label_ts), axis=1)\n",
    "max_idx = np.argmax(mean_act)\n",
    "print(\"Label with strongest average activity:\", labels[max_idx].name)\n",
    "\n",
    "# Also, you can visualize a label-based summary\n",
    "stc_label = mne.labels_to_stc(\n",
    "    labels, mean_act, \n",
    "    subject='fsaverage'\n",
    ")\n",
    "brain = stc_label.plot(\n",
    "    subject='fsaverage', \n",
    "    subjects_dir=subject_dir, \n",
    "    hemi='split', \n",
    "    time_viewer=True,\n",
    "    clim={'kind': 'value', 'pos_lims': [0, 0.5, 1]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well maybe the MI makes sense on just the raw sensor data. But maybe it would make more sense to look at it in terms of the coefficients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
