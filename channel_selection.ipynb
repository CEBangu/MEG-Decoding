{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datahandling import BcomMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_i_16-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_me_34-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_re_144-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_sa_52-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ra_42-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_le_24-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "7 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_i_116-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_a_112-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ri_146-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_a_12-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "17 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_si_56-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_sa_152-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ma_132-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "18 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ra_142-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_mi_36-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_te_164-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_e_14-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_si_156-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_se_54-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_li_126-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ta_162-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_li_26-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ti_66-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ma_32-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "18 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_re_44-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ri_46-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ta_62-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_ti_166-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "6 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_e_114-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_mi_136-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_te_64-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_se_154-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_la_22-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_la_122-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_me_134-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT/BCOM_18_2_le_124-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "7 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "dir = '/Volumes/@neurospeech/PROJECTS/BCI/BCOM/DATA_ANALYZED/EVOKED/DATA/WITHOUT_BADS/COVERT'\n",
    "epo_files = []\n",
    "subjects = ['BCOM_18_2'] # focus on one because the head thing for the mutliple trials is not working atm. \n",
    "avoid_reading = False\n",
    "data = BcomMEG(dir=dir, subjects=subjects, avoid_reading=avoid_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "178 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "123 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "# first, sepreate out the conditions\n",
    "a_labels = [a for a in data.data['BCOM_18_2'].keys() if 'a' in a]\n",
    "e_labels = [e for e in data.data['BCOM_18_2'].keys() if 'e' in e]\n",
    "i_labels = [i for i in data.data['BCOM_18_2'].keys() if 'i' in i]\n",
    "\n",
    "for subject in data.data:\n",
    "    a_epochs = mne.concatenate_epochs([data.data[subject][a] for a in a_labels])\n",
    "    e_epochs = mne.concatenate_epochs([data.data[subject][e] for e in e_labels])\n",
    "    i_epochs = mne.concatenate_epochs([data.data[subject][i] for i in i_labels])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a threshold of 3.043980\n",
      "stat_fun(H1): min=2.5895308760466117e-05 max=9.295301215841619\n",
      "Running initial clustering â€¦\n",
      "Found 677 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/tvmmnqs17399g3n7wyy0pq0c0000gn/T/ipykernel_80135/2382917169.py:4: RuntimeWarning: Ignoring argument \"tail\", performing 1-tailed F-test\n",
      "  T_obs, clusters, cluster_p_values, H0 = permutation_cluster_test(permuataion_collection, n_permutations=2000, tail=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d68bd0dd814484bf3ef6620f207333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/1999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first, sepreate out the conditions\n",
    "a_labels = []\n",
    "e_labels = []\n",
    "i_labels = []\n",
    "for subject in data.data.keys():\n",
    "    for condition in data.data[subject].keys():\n",
    "        if 'a' in condition:\n",
    "            a_labels.append(condition)\n",
    "        elif 'e' in condition:\n",
    "            e_labels.append(condition)\n",
    "        elif 'i' in condition:\n",
    "            i_labels.append(condition)\n",
    "\n",
    "a_labels = set(a_labels)\n",
    "i_labels = set(i_labels)\n",
    "e_labels = set(e_labels)\n",
    "\n",
    "a_epochs = []\n",
    "e_epochs = []\n",
    "i_epochs = []\n",
    "\n",
    "for subject in data.data:\n",
    "    a_epochs.append(mne.concatenate_epochs([data.data[subject][a] for a in a_labels if a in data.data[subject].keys()]))\n",
    "    e_epochs.append(mne.concatenate_epochs([data.data[subject][e] for e in e_labels if e in data.data[subject].keys()]))\n",
    "    i_epochs.append(mne.concatenate_epochs([data.data[subject][i] for i in i_labels if i in data.data[subject].keys()]))\n",
    "\n",
    "a_epochs = mne.concatenate_epochs(a_epochs)\n",
    "e_epochs = mne.concatenate_epochs(e_epochs)\n",
    "i_epochs = mne.concatenate_epochs(i_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_test\n",
    "\n",
    "permuataion_collection = [a_epochs.get_data(), e_epochs.get_data(), i_epochs.get_data()]\n",
    "T_obs, clusters, cluster_p_values, H0 = permutation_cluster_test(permuataion_collection, n_permutations=2000, tail=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_sensors = np.where(cluster_p_values < 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "num_a = len(a_epochs)\n",
    "num_e = len(e_epochs)\n",
    "num_i = len(i_epochs)\n",
    "min_trials = (min(num_a, num_e, num_i))\n",
    "\n",
    "a_rand = a_epochs[np.random.choice(num_a, min(num_a, num_e, num_i), replace=False)]\n",
    "e_rand = e_epochs[np.random.choice(num_e, min(num_a, num_e, num_i), replace=False)]\n",
    "i_rand = i_epochs[np.random.choice(num_i, min(num_a, num_e, num_i), replace=False)]\n",
    "\n",
    "a_data = a_rand.get_data()\n",
    "e_data = e_rand.get_data()\n",
    "i_data = i_rand.get_data()\n",
    "\n",
    "a_flat = a_data.reshape(a_data.shape[0], -1)\n",
    "e_flat = e_data.reshape(e_data.shape[0], -1)\n",
    "i_flat = i_data.reshape(i_data.shape[0], -1)\n",
    "\n",
    "\n",
    "X = np.vstack([a_flat, e_flat, i_flat])\n",
    "y = np.concatenate([np.ones(min_trials), np.ones(min_trials)*2, np.ones(min_trials)*3])\n",
    "mi_scores = mutual_info_classif(X, y, random_state=0)\n",
    "important_sensors = np.argsort(mi_scores)[-10:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_reshaped = mi_scores.reshape(a_data.shape[1], a_data.shape[2])\n",
    "sensor_mi_scores_reshaped = mi_reshaped.mean(axis=1)\n",
    "important_sensors = np.argsort(sensor_mi_scores_reshaped)[-10:]\n",
    "sensor_names = a_epochs.info['ch_names']\n",
    "important_sensor_names = [sensor_names[i] for i in important_sensors]\n",
    "print(important_sensor_names)\n",
    "sensor_mi_scores_reshaped[important_sensors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne.channels\n",
    "\n",
    "\n",
    "important_sensor_names\n",
    "sensor_mi_scores_reshaped[important_sensors]\n",
    "\n",
    "info = a_epochs.info\n",
    "picks = mne.pick_channels(info['ch_names'], include=important_sensor_names)\n",
    "\n",
    "pos = mne.channels.layout._find_topomap_coords(info, picks)\n",
    "\n",
    "data = np.array(sensor_mi_scores_reshaped[important_sensors])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_topomap(data, pos, axes=ax, show=False, cmap='viridis', contours=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def scalogram_dereconstruction(data, wavelet='db4', level=7):\n",
    "    # First decompose\n",
    "    coefficients = pywt.wavedec(data, wavelet, level=level)\n",
    "    coefficients[-1] = np.zeros_like(coefficients[-1]) #d1 #get rid of these two as in Dash et al 2020.\n",
    "    coefficients[-2] = np.zeros_like(coefficients[-2]) #d2\n",
    "    # Reconstruct\n",
    "    reconstructed_signal = pywt.waverec(coefficients, wavelet)[:len(data)]\n",
    "    return reconstructed_signal\n",
    "\n",
    "def scalogram_cwt(processed_data, wavelet, B, C, sampling_rate, log_samples):\n",
    "    wavelet = f'{wavelet}{B}-{C}'\n",
    "    sampling_period = 1/sampling_rate\n",
    "    frequencies = np.logspace(np.log10(1), np.log10(sampling_rate/2), log_samples)\n",
    "    scales = pywt.central_frequency(wavelet=wavelet)/ (frequencies * sampling_period)\n",
    "    coefficients, _ = pywt.cwt(data=processed_data, scales=scales, wavelet=wavelet, sampling_period=sampling_period)\n",
    "    return coefficients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 247, 241)\n",
      "(108, 247, 100, 241)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(a_data.shape) # epochs, sensors, time\n",
    "\n",
    "\n",
    "#Precompute to hopefully make it faster. In any case, this is super easy to parallelize.\n",
    "log_samples = 100\n",
    "a_coefficients = np.zeros([a_data.shape[0], a_data.shape[1], log_samples, a_data.shape[2]])\n",
    "print(a_coefficients.shape)\n",
    "wavelet = 'cmor1.0-1.0'\n",
    "sampling_rate = 300\n",
    "sampling_period = 1/sampling_rate\n",
    "frequencies = np.logspace(np.log10(1), np.log10(sampling_rate/2), log_samples)\n",
    "scales = pywt.central_frequency(wavelet=wavelet)/ (frequencies * sampling_period)\n",
    "\n",
    "for epoch, _ in enumerate(a_data): # ALMOST 6 MINUTES FOR 108 EPOCHS!! Parrallelize this or it will take forever. \n",
    "    # print(epoch)\n",
    "    for channel, _ in enumerate(a_data[epoch]):\n",
    "        # print(a_data[epoch][channel])\n",
    "        reconstructed_signal = scalogram_dereconstruction(a_data[epoch][channel], wavelet='db4', level=5) # this doesn't change dims so might be possible to map\n",
    "        # print(reconstructed_signal.shape)\n",
    "        coefficients, _ = pywt.cwt(data=reconstructed_signal, scales=scales, wavelet=wavelet, sampling_period=sampling_period)\n",
    "        # print(coefficients.shape) # log_samplesx241\n",
    "        a_coefficients[epoch][channel] = abs(coefficients)\n",
    "    #     print(a_coefficients)\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('a_coefficients.npy', a_coefficients) # 17 seconds and about 5GB - compression doesn't help for storage and takes way longer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = [a_data, e_data, i_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so this works, but run with extreme caution or it will crash your computer! Would be better to do it on the cluster I think, but at least for testing it worked (and I saved the results lol)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_epoch(epoch_data, scales, wavelet, sampling_period, log_samples):\n",
    "    '''Takes in an entire epoch and processes it into scalogram coefficients'''\n",
    "    epoch_coefficients = np.zeros([epoch_data.shape[0], log_samples, epoch_data.shape[1]]) # channels, scales, time for each epoch\n",
    "    epoch_data = np.array(epoch_data, copy=True) # Make the array writable\n",
    "    \n",
    "    for channel, channel_data in enumerate(epoch_data):\n",
    "        reconstructed_signal = scalogram_dereconstruction(channel_data, wavelet='db4', level=5)\n",
    "        coefficients, _ = pywt.cwt(data=reconstructed_signal, scales=scales, wavelet=wavelet, sampling_period=sampling_period)\n",
    "        epoch_coefficients[channel] = abs(coefficients)\n",
    "    \n",
    "    return epoch_coefficients\n",
    "\n",
    "def process_categories(data, scales, wavelet, sampling_period, log_samples):\n",
    "    '''Takes in an entire category and processes it into scalogram coefficients'''\n",
    "    results = Parallel(n_jobs=3)(\n",
    "        delayed(process_epoch)(\n",
    "            epoch_data=data[category],\n",
    "            scales=scales,\n",
    "            wavelet=wavelet,\n",
    "            sampling_period=sampling_period,\n",
    "            log_samples=log_samples\n",
    "        ) for category in range(len(data))\n",
    "    )\n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=3)(\n",
    "    delayed(process_categories)(\n",
    "        data=data_array, \n",
    "        scales=scales, \n",
    "        wavelet=wavelet, \n",
    "        sampling_period=sampling_period, \n",
    "        log_samples=log_samples\n",
    "    ) for data_array in all_categories\n",
    ")\n",
    "\n",
    "a_coefficients, e_coefficients, i_coefficients = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('a_coefficients_18_2_Feb10.npy', a_coefficients)\n",
    "# np.save('e_coefficients_18_2_Feb10.npy', e_coefficients)\n",
    "# np.save('i_coefficients_18_2_Feb10.npy', i_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok so where in the brain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : <SourceSpaces: [<surface (lh), n_vertices=163842, n_used=4098>, <surface (rh), n_vertices=163842, n_used=4098>] MRI (surface RAS) coords, subject 'fsaverage', ~35.0 MB>\n",
      "MRI -> head transform : /opt/homebrew/Caskroom/miniconda/base/envs/mne/lib/python3.12/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : instance of ConductorModel\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Read 2 source spaces a total of 8196 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "    0.999994 0.003552 0.000202      -1.76 mm\n",
      "    -0.003558 0.998389 0.056626      31.09 mm\n",
      "    -0.000001 -0.056626 0.998395      39.60 mm\n",
      "    0.000000 0.000000 0.000000       1.00\n",
      "\n",
      "Read 247 MEG channels from info\n",
      "105 coil definitions read\n",
      "Coordinate transformation: MEG device -> head\n",
      "    0.994570 -0.096133 -0.039854      -2.40 mm\n",
      "    0.101937 0.977019 0.187196     -35.72 mm\n",
      "    0.020942 -0.190242 0.981514      58.09 mm\n",
      "    0.000000 0.000000 0.000000       1.00\n",
      "MEG coil definitions created in head coordinates.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model instance of ConductorModel is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface (will take a few...)\n",
      "Checking surface interior status for 4098 points...\n",
      "    Found  999/4098 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found    0/4098 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found    0/3099 points outside using surface Qhull\n",
      "    Found    0/3099 points outside using solid angles\n",
      "    Total 4098/4098 points inside the surface\n",
      "Interior check completed in 744.4 ms\n",
      "Checking surface interior status for 4098 points...\n",
      "    Found  906/4098 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found    0/4098 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found    0/3192 points outside using surface Qhull\n",
      "    Found    0/3192 points outside using solid angles\n",
      "    Total 4098/4098 points inside the surface\n",
      "Interior check completed in 758.1 ms\n",
      "\n",
      "Checking surface interior status for 247 points...\n",
      "    Found   0/247 points inside  an interior sphere of radius   83.4 mm\n",
      "    Found  43/247 points outside an exterior sphere of radius  133.7 mm\n",
      "    Found 204/204 points outside using surface Qhull\n",
      "    Found   0/  0 points outside using solid angles\n",
      "    Total 0/247 points inside the surface\n",
      "Interior check completed in 17.3 ms\n",
      "\n",
      "Composing the field computation matrix...\n",
      "Computing MEG at 8196 source locations (free orientations)...\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "subject_dir = os.path.expanduser('~/mne_data/MNE-fsaverage-data')\n",
    "bem_dir = os.path.expanduser('~/mne_data/MNE-fsaverage-data/')\n",
    "# head transformation, need to use average because no MRIs\n",
    "transformation = 'fsaverage'\n",
    "\n",
    "# standard source space and BEM model - \"Boundary Element Method\" model. i.e., a realistic head model to use for source localization. \n",
    "# apparently it deifnes the el\n",
    "\n",
    "src = mne.setup_source_space(subject='fsaverage', spacing='oct6', subjects_dir=subject_dir) # 5 mins\n",
    "\n",
    "bem = mne.make_bem_model(subject='fsaverage', subjects_dir=bem_dir) \n",
    "\n",
    "bem = mne.make_bem_solution(bem)\n",
    "\n",
    "# only for the chosen sensors\n",
    "\n",
    "picks = mne.pick_channels(info['ch_names'], include=important_sensor_names)\n",
    "\n",
    "# forward model\n",
    "\n",
    "fwd = mne.make_forward_solution(info=a_epochs.info, trans=transformation, src=src, bem=bem, eeg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10 out of 247 channels remain after picking\n"
     ]
    }
   ],
   "source": [
    "# get it for only certain channels\n",
    "\n",
    "picks = mne.pick_channels(fwd['info']['ch_names'], include=important_sensor_names)\n",
    "fwd_selected = mne.pick_channels_forward(fwd, include=important_sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data rank from 247 -> 247\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using DIAGONAL_FIXED\n",
      "    MAG regularization : 0.1\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "    MAG regularization : 0.1\n",
      "    MAG regularization : 0.1\n",
      "    MAG regularization : 0.1\n",
      "Number of samples used : 28197\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -1368.100\n",
      "   empirical: -1368.259\n",
      "   diagonal_fixed: -1427.716\n",
      "selecting best estimator: shrunk\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 10 channels.\n",
      "    10 out of 10 channels remain after picking\n",
      "Selected 10 channels\n",
      "Creating the depth weighting matrix...\n",
      "    10 magnetometer or axial gradiometer channels\n",
      "    limit = 7980/8196 = 10.006894\n",
      "    scale = 4.50088e-12 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.5e-16 (2.2e-16 eps * 10 dim * 0.16  max singular value)\n",
      "    Estimated rank (mag): 10\n",
      "    MAG: rank 10 computed from 10 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 1.59682\n",
      "    scaling factor to adjust the trace = 8.10551e+17 (nchan = 10 nzero = 0)\n"
     ]
    }
   ],
   "source": [
    "# Computing the inverse model:\n",
    "\n",
    "noise_cov = mne.compute_covariance(a_epochs, method='auto')\n",
    "\n",
    "# create an inverse operator to convert signals to brain activity\n",
    "\n",
    "inv = mne.minimum_norm.make_inverse_operator(info=a_epochs.info, forward=fwd_selected, noise_cov=noise_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lambda2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m9.0\u001b[39m \u001b[38;5;66;03m# regularization parameter\u001b[39;00m\n\u001b[1;32m      4\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdSPM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# or \"dSPM\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stc \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mminimum_norm\u001b[38;5;241m.\u001b[39mapply_inverse(a_epochs\u001b[38;5;241m.\u001b[39maverage(), \u001b[43minv\u001b[49m, lambda2, method)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inv' is not defined"
     ]
    }
   ],
   "source": [
    "# computing source esitmation\n",
    "\n",
    "lambda2 = 1.0 / 9.0 # regularization parameter\n",
    "method = \"dSPM\" # or \"dSPM\"\n",
    "\n",
    "stc = mne.minimum_norm.apply_inverse(a_epochs.average(), inv, lambda2, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... Idk if this shows what I want it to show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.26156745 3.43162634 4.04986332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x17bd27a50> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3d2827b40> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160490780> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160491b10> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160496630> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160497860> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x1604981b0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x160499c70> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x396aa32a0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x16049ba50> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3bc36c2f0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x3bc3320b0> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "brain = stc.plot(hemi='split', subjects_dir=subject_dir, subject='fsaverage', time_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak activation at vertex 86178 at 0.21666666666666673 seconds\n"
     ]
    }
   ],
   "source": [
    "peak_vertex, peak_time = stc.get_peak()\n",
    "print(f\"Peak activation at vertex {peak_vertex} at {peak_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 35 labels from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/label/lh.aparc.annot\n",
      "   read 34 labels from /Users/ciprianbangu/mne_data/MNE-fsaverage-data/fsaverage/label/rh.aparc.annot\n",
      "Extracting time courses for 68 labels (mode: mean)\n",
      "Label with strongest average activity: lateraloccipital-lh\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Read labels for fsaverage (Desikan-Killiany \"aparc\" parcellation)\n",
    "labels = mne.read_labels_from_annot(\n",
    "    subject='fsaverage', \n",
    "    parc='aparc', \n",
    "    subjects_dir=subject_dir\n",
    ")\n",
    "\n",
    "# one of them is missing i guess?\n",
    "labels = [label for label in labels if 'unknown' not in label.name]\n",
    "\n",
    "# Extract mean time course from each label\n",
    "label_ts = mne.extract_label_time_course(\n",
    "    stc, \n",
    "    labels, \n",
    "    src=src, \n",
    "    mode='mean'\n",
    ")\n",
    "# label_ts: shape (n_labels, n_times)\n",
    "\n",
    "# Find label with largest mean activity over time\n",
    "mean_act = np.mean(np.abs(label_ts), axis=1)\n",
    "max_idx = np.argmax(mean_act)\n",
    "print(\"Label with strongest average activity:\", labels[max_idx].name)\n",
    "\n",
    "# Also, you can visualize a label-based summary\n",
    "stc_label = mne.labels_to_stc(\n",
    "    labels, mean_act, \n",
    "    subject='fsaverage'\n",
    ")\n",
    "brain = stc_label.plot(\n",
    "    subject='fsaverage', \n",
    "    subjects_dir=subject_dir, \n",
    "    hemi='split', \n",
    "    time_viewer=True,\n",
    "    clim={'kind': 'value', 'pos_lims': [0, 0.5, 1]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well maybe the MI makes sense on just the raw sensor data. But maybe it would make more sense to look at it in terms of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
