{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e952a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "from pymatreader import read_mat\n",
    "import numpy as np\n",
    "import os\n",
    "from autoreject import AutoReject\n",
    "from BCOM_processing.SCRIPTS.functions import Epoching\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Volumes/BCOM\"\n",
    "\n",
    "output_path = op.join(root, \"ciprian_project/data_analyzed/evoked/data\")\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "raws_path = op.join(root, \"BCOM/DATA_RAW\")\n",
    "cleaned_path = op.join(root, 'ciprian_project/data_analyzed/preprocessed')\n",
    "\n",
    "# this channel has a weird position in the helmet coordinate space,\n",
    "# so the thinking is to not interpolate it here\n",
    "bad_localization_channel = \"MEG 173\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30143a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interploate_no_bad_loc(raw, bad_loc_chan):\n",
    "    bads_list = raw.info[\"bads\"]\n",
    "    bads_list_cleaned = [bad for bad in bads_list if bad != bad_loc_chan]\n",
    "    raw.info[\"bads\"] = bads_list_cleaned\n",
    "    raw.interpolate_bads()\n",
    "    raw.info['bads'].append(bad_loc_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fe15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directories\n",
    "triggers_pd = pd.read_csv(op.join(root, \"BCOM/PROTOCOL/trigger_labels.csv\"), sep=';')\n",
    "\n",
    "produce_triggers = triggers_pd['produce_head'].to_list() #the csv already has names\n",
    "\n",
    "read_triggers = triggers_pd['read_head'].to_list()\n",
    "\n",
    "syllables = triggers_pd['syllable'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed567c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_tmin=-0.4\n",
    "epoch_tmax=0.8\n",
    "reject_dict = dict(mag=5e-12)\n",
    "\n",
    "subjects = [x for x in os.listdir(cleaned_path) if x[0] == 'B']\n",
    "subjects.sort()\n",
    "numbers = [x[-2:] for x in subjects]\n",
    "\n",
    "conditions = ['OVERT', 'COVERT']\n",
    "cleanings = ['WITHOUT_BADS', 'WITH_BADS']\n",
    "\n",
    "evoked_output = os.path.join(output_path, 'DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trigger in produce_triggers:\n",
    "    for sub in subjects:\n",
    "        for i in range(2, 5):\n",
    "            f_path = os.path.join(cleaned_path, sub, str(i), \"subject_cleaned_raw.fif\")\n",
    "            cleaned_raw = mne.io.read_raw_fif(f_path, preload=True)\n",
    "\n",
    "            path = os.path.join(raws_path, sub, \"MEG\", sub, \"BCom\")\n",
    "\n",
    "            for file in os.listdir(path):\n",
    "                if os.path.isdir(os.path.join(path, file)):\n",
    "                    if sub == 'BCOM_08': #something special about this one\n",
    "                        mat_path = os.path.join(path, file, str(i + 1))\n",
    "                    else:\n",
    "                        mat_path = os.path.join(path, file, str(i))\n",
    "                    break\n",
    "\n",
    "            events = np.load(op.join(cleaned_path, sub, str(i), 'resampled_events.npy'))\n",
    "\n",
    "            produce_trigger = trigger\n",
    "            read_trigger = trigger - 100\n",
    "\n",
    "            all_read_events = [event for event in events if int(event[2]) == int(read_trigger)] \n",
    "            all_produce_events = [event for event in events if int(event[2]) == int(produce_trigger)] \n",
    "\n",
    "            Epo = Epoching(mat_path, events)\n",
    "\n",
    "            bad_idx = Epo.get_bad_syll(raws_folder, sub, read_trigger, read_triggers, syllables, i)\n",
    "\n",
    "            cleaned_read_events = all_read_events.copy()\n",
    "            cleaned_produce_events = all_produce_events.copy()\n",
    "            \n",
    "            for idx in bad_idx[::-1]:\n",
    "                cleaned_read_events.pop(idx)\n",
    "                cleaned_produce_events.pop(idx)\n",
    "\n",
    "            events_list = []\n",
    "\n",
    "            all_read_events_covert = np.array([event for event in all_read_events if not Epo.is_overt(event)]) #gets the trial which contains the overt phase, and then returns the ones that are covert\n",
    "            events_list.append(all_read_events_covert)\n",
    "            all_read_events_overt = np.array([event for event in all_read_events if Epo.is_overt(event)]) #gets the trial which contains the overt phase, and then returns the ones that are overt\n",
    "            events_list.append(all_read_events_overt)\n",
    "\n",
    "            all_produce_events_covert = np.array([event for event in all_produce_events if not Epo.is_overt(event)]) #same thing with th eproduce events\n",
    "            events_list.append(all_produce_events_covert)\n",
    "            all_produce_events_overt = np.array([event for event in all_produce_events if Epo.is_overt(event)])\n",
    "            events_list.append(all_produce_events_overt)\n",
    "\n",
    "            cleaned_read_events_covert = np.array([event for event in cleaned_read_events if not Epo.is_overt(event)]) #same thing just with the cleaned files instead\n",
    "            events_list.append(cleaned_read_events_covert)\n",
    "            cleaned_read_events_overt = np.array([event for event in cleaned_read_events if Epo.is_overt(event)])\n",
    "            events_list.append(cleaned_read_events_overt)\n",
    "\n",
    "            cleaned_produce_events_covert = [event for event in cleaned_produce_events if not Epo.is_overt(event)]\n",
    "            events_list.append(cleaned_produce_events_covert)\n",
    "            cleaned_produce_events_overt = [event for event in cleaned_produce_events if Epo.is_overt(event)]\n",
    "            events_list.append(cleaned_produce_events_overt)\n",
    "\n",
    "            picks = mne.pick_types(cleaned_raw.info, meg=True, eeg=False, stim=False, eog=False, ecg=False, misc=False) #which channels to pick\n",
    "\n",
    "            for idx in range(len(events_list)): #setting the indexes for the different conditions\n",
    "                evs = events_list[idx]\n",
    "                if idx < 4:\n",
    "                    cleaning = 'WITH_BADS'\n",
    "                elif idx > 3:\n",
    "                    cleaning = 'WITHOUT_BADS'\n",
    "                if idx % 2 == 0:\n",
    "                    condition = 'COVERT'\n",
    "                elif idx % 2 == 1:\n",
    "                    condition = 'OVERT'\n",
    "\n",
    "                if len(evs) > 0:\n",
    "                    epochs_main = mne.Epochs(cleaned_raw, events=evs, reject=reject_dict, picks=picks, baseline=None,\n",
    "                                         tmin=epoch_tmin, tmax=epoch_tmax, preload=True) #creates the epochs given the data and the specified parameters\n",
    "\n",
    "                    if len(epochs_main) != 0:\n",
    "                        ar = AutoReject(verbose=True, picks=picks, n_jobs=3) #initializes the autoreject class\n",
    "                        # ransac = Ransac(verbose=True, picks=picks, n_jobs=3)\n",
    "                        try:\n",
    "                            epochs_clean = ar.fit_transform(epochs_main) # automatically identifies the bad data\n",
    "                            # epochs_clean = ransac.fit_transform(epochs_main)\n",
    "                        except:\n",
    "                            epochs_clean = epochs_main #if that doesn't work, then just use the original epochs\n",
    "\n",
    "                        trigger_index = produce_triggers.index(produce_trigger)\n",
    "                        if len(epochs_clean) != 0:\n",
    "                            syll_label = epochs_main.events[0][2]\n",
    "                            epochs_clean.save(op.join(evo_output, cleaning, condition, sub+'_'+str(i)+'_'+syllables[trigger_index]+'_'+str(syll_label)+'-epo.fif'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
